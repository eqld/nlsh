# Neural Shell (nlsh) Configuration

# Shell to use for command generation
# Override with environment variable: NLSH_SHELL
shell: "bash"  # Options: bash, zsh, fish, powershell

# LLM Backends
backends:
  # OpenAI API (text-only)
  - name: "openai"
    url: "https://api.openai.com/v1"
    api_key: $OPENAI_API_KEY   # Will be replaced with environment variable
    model: "gpt-3.5-turbo"     # Or gpt-4, etc.
    supports_vision: false     # This model doesn't support image processing

  # OpenAI GPT-4 Vision (supports images)
  - name: "openai-gpt4-vision"
    url: "https://api.openai.com/v1"
    api_key: $OPENAI_API_KEY   # Will be replaced with environment variable
    model: "gpt-4-vision-preview"  # Vision-capable model
    supports_vision: true      # This model supports image processing

  # Local Ollama
  - name: "local-ollama"
    url: "http://localhost:11434/v1"
    api_key: "ollama"          # Ollama doesn't require an API key
    model: "llama3"            # Or any other model you have in Ollama
    supports_vision: false     # Most Ollama models don't support vision

  # Local Ollama with LLaVA (vision model)
  - name: "local-llava"
    url: "http://localhost:11434/v1"
    api_key: "ollama"          # Ollama doesn't require an API key
    model: "llava"             # Vision-capable model
    supports_vision: true      # This model supports image processing

  # DeepSeek reasoner (reasoning model)
  - name: "deepseek-reasoner"
    url: "https://api.deepseek.com/v1"
    api_key: $DEEPSEEK_API_KEY # Will be replaced with environment variable
    model: "deepseek-reasoner"
    is_reasoning_model: true   # This flag is required to be able to display reasoning tokens in verbose mode
    supports_vision: false     # This model doesn't support image processing

# Default backend to use (index in the backends list, starting from 0)
# Override with environment variable: NLSH_DEFAULT_BACKEND
default_backend: 0

# STDIN processing configuration
# Override with environment variables: NLSH_STDIN_DEFAULT_BACKEND, NLSH_STDIN_DEFAULT_BACKEND_VISION
stdin:
  # Default backend for text STDIN processing (optional)
  # Falls back to global default_backend if not specified
  default_backend: 0
  
  # Default backend for image STDIN processing (optional)
  # Falls back to stdin.default_backend or global default_backend if not specified
  # Should point to a backend with supports_vision: true
  default_backend_vision: 1

# Configuration for the 'nlgc' (Neural Git Commit) command
# Override with environment variable: NLSH_NLGC_INCLUDE_FULL_FILES (true/false)
# Override with environment variable: NLSH_NLGC_LANGUAGE
nlgc:
  # Whether to include the full content of changed files in the prompt
  # sent to the LLM for commit message generation. Provides more context
  # but increases token usage significantly.
  include_full_files: true
  
  # Language for commit message generation (e.g., "Spanish", "French", "German")
  # Set to null or omit for default behavior (English)
  # Can be overridden with --language/-l flag or NLSH_NLGC_LANGUAGE env var
  language: null
