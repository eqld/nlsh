# Neural Shell (nlsh) Configuration

# Shell to use for command generation
# Override with environment variable: NLSH_SHELL
shell: "bash"  # Options: bash, zsh, fish, powershell

# LLM Backends
backends:
  # OpenAI API
  - name: "openai"
    url: "https://api.openai.com/v1"
    api_key: $OPENAI_API_KEY   # Will be replaced with environment variable
    model: "gpt-3.5-turbo"     # Or gpt-4, etc.

  # Local Ollama
  - name: "local-ollama"
    url: "http://localhost:11434/v1"
    api_key: "ollama"          # Ollama doesn't require an API key
    model: "llama3"            # Or any other model you have in Ollama

  # DeepSeek reasoner (reasoning model)
  - name: "deepseek-reasoner"
    url: "https://api.deepseek.com/v1"
    api_key: $DEEPSEEK_API_KEY # Will be replaced with environment variable
    model: "deepseek-reasoner"
    is_reasoning_model: true   # This flag is required to be able to display reasoning tokens in verbose mode

# Default backend to use (index in the backends list, starting from 0)
# Override with environment variable: NLSH_DEFAULT_BACKEND
default_backend: 0

# Configuration for the 'nlgc' (Neural Git Commit) command
# Override with environment variable: NLSH_NLGC_INCLUDE_FULL_FILES (true/false)
nlgc:
  # Whether to include the full content of changed files in the prompt
  # sent to the LLM for commit message generation. Provides more context
  # but increases token usage significantly.
  include_full_files: true
